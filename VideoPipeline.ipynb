{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions from `ImagePipeline.ipynb`\n",
    "\n",
    "\n",
    "With video format, we work with a series of images instead of just one image. Lane lines from previous image can be used to better estimate present location because the car shows continuous motion from one point to another. Thus, we can make our algorithm more robust using past data. `draw_lanes()` function has been updated to combine present lane location info with past info to make better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\n",
    "    Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = draw_lines(img, lines, [255, 0, 0], 2);\n",
    "    \n",
    "    return line_img, lines\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n",
    "    \"\"\"\n",
    "    Draw an array of line segments on a blank image\n",
    "    \"\"\"\n",
    "    line_img=np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8);\n",
    "    if lines is None:\n",
    "        return line_img\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "    return line_img\n",
    "\n",
    "def slope_thresholding(img,lines):\n",
    "    \"\"\"\n",
    "    This function isolates somewhat vertical line segments.\n",
    "    Then, it divides raw line segments into left and right lane.\n",
    "    \n",
    "    Input: \n",
    "    img= Color image from dashcam\n",
    "    lines= Set of line segments which denote parts of lane lines\n",
    "    \"\"\"\n",
    "    lane_raw=[];\n",
    "    \n",
    "    #Check if no raw lines were detected\n",
    "    if lines is None:\n",
    "        raw_lane_img= draw_lines(img, lines, [0, 255, 0], 2);\n",
    "        return raw_lane_img, [], []\n",
    "    \n",
    "    #Ignore segments which are somewhat horizontal\n",
    "    for pts in lines:\n",
    "        for x1,y1,x2,y2 in pts:\n",
    "            m=(y2-y1)/(x2-x1)\n",
    "            if m>.25 or m<-.25:\n",
    "                lane_raw.append(pts)\n",
    "    \n",
    "    #Separate left and right lanes\n",
    "    left_lane_raw=[];\n",
    "    right_lane_raw=[];\n",
    "    for pts in lane_raw:\n",
    "        for x1,y1,x2,y2 in pts:\n",
    "            slope=((y2-y1)/(x2-x1));\n",
    "            if slope<0:\n",
    "                left_lane_raw.append(pts)\n",
    "            else:\n",
    "                right_lane_raw.append(pts)\n",
    "                \n",
    "    left_raw_img = draw_lines(img, left_lane_raw, [0, 255, 0], 2)\n",
    "    right_raw_img = draw_lines(img, right_lane_raw, [0, 0, 255], 2)\n",
    "    \n",
    "    \n",
    "    raw_lane_img = weighted_img(left_raw_img,right_raw_img,1,1,0)\n",
    "    return raw_lane_img, left_lane_raw, right_lane_raw\n",
    "    \n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "\n",
    "def draw_lanes(img, left_lane_raw, right_lane_raw, pastLane):\n",
    "    \"\"\"\n",
    "    This function plots left and right lane lines on dashcam image\n",
    "\n",
    "    The raw lane lines are aggregated into single line segments denoting lane lines\n",
    "    \"\"\"\n",
    "    \n",
    "    #Find Top and Bottom x values of the lane\n",
    "    #y_top=lines[0][0][1]\n",
    "    #y_bottom=lines[0][0][1]\n",
    "    #for pts in lines:\n",
    "    #    for x1,y1,x2,y2 in pts:\n",
    "    #        if y_top>y1:\n",
    "    #            y_top=y1\n",
    "    #        if y_bottom<y1:\n",
    "    #            y_bottom=y1\n",
    "    #        if y_top>y2:\n",
    "    #            y_top=y2\n",
    "    #        if y_bottom<y2:\n",
    "    #            y_bottom=y2\n",
    "    y_bottom=img.shape[0]\n",
    "    y_top=.65*img.shape[0]\n",
    "\n",
    "    presentlane=[];\n",
    "    #Average raw Lane Lines to get single equation for left and right lanes\n",
    "    presentlane.append(avg_line(left_lane_raw)) #line in form x,y,dx,dy\n",
    "    presentlane.append(avg_line(right_lane_raw))\n",
    "    \n",
    "    #Average Lane lines according to their past position\n",
    "    lane=avg_lanes_time(presentlane,pastLane)\n",
    "    \n",
    "    #Calculate final lane end points\n",
    "    finallane=[]\n",
    "    if not(len(lane[0])==0):\n",
    "        left_x,left_y,left_dx,left_dy=lane[0]\n",
    "        t1=(y_top-left_y)/left_dy\n",
    "        t2=(y_bottom-left_y)/left_dy\n",
    "        left_lane=np.array([(left_x+t1*left_dx),y_top,(left_x+t2*left_dx),y_bottom]);\n",
    "        left_lane=left_lane.astype(int)\n",
    "        finallane.append([left_lane])\n",
    "    \n",
    "    if not(len(lane[1])==0):\n",
    "        right_x,right_y,right_dx,right_dy=lane[1]\n",
    "        t1=(y_top-right_y)/right_dy\n",
    "        t2=(y_bottom-right_y)/right_dy\n",
    "        right_lane=np.array([(right_x+t1*right_dx),y_top,(right_x+t2*right_dx),y_bottom]);\n",
    "        right_lane=right_lane.astype(int)\n",
    "        finallane.append([right_lane])\n",
    "    \n",
    "    lane_img=draw_lines(img, finallane);    \n",
    "    return lane_img, lane\n",
    "\n",
    "def avg_line(lines):\n",
    "    if (len(lines)==0):\n",
    "        return []\n",
    "    \n",
    "    avg_pt=np.array([0,0])\n",
    "    avg_dirn=np.array([0,0])\n",
    "    for pts in lines:\n",
    "        for x1,y1,x2,y2 in pts:\n",
    "            dirn=np.array([x2-x1,y2-y1])\n",
    "            avg_dirn=avg_dirn+(dirn/np.linalg.norm(dirn))\n",
    "            avg_pt=avg_pt+[(x1+x2)/2.0,(y1+y2)/2.0]\n",
    "    avg_pt=avg_pt/len(lines)\n",
    "    avg_dirn=avg_dirn/len(lines)\n",
    "    x=avg_pt[0]\n",
    "    y=avg_pt[1]\n",
    "    dx=avg_dirn[0]\n",
    "    dy=avg_dirn[1]\n",
    "    \n",
    "    #print (x,y,dx,dy)\n",
    "    return [x,y,dx,dy]\n",
    "\n",
    "def avg_lanes_time(present,past,w=.25):\n",
    "    avg_lane=[];\n",
    "    #First compare left lanes\n",
    "    if len(present[0])==0 and len(past[0])==0:\n",
    "        avg_lane.append([])\n",
    "    elif len(present[0])==0:\n",
    "        avg_lane.append(past[0])\n",
    "    elif len(past[0])==0:\n",
    "        avg_lane.append(present[0])\n",
    "    else:\n",
    "        arr=w*np.array(present[0])+(1-w)*np.array(past[0])\n",
    "        avg_lane.append(arr.tolist())\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Then compare right lanes\n",
    "    if len(present[1])==0 and len(past[1])==0:\n",
    "        avg_lane.append([])\n",
    "    elif len(present[1])==0:\n",
    "        avg_lane.append(past[1])\n",
    "    elif len(past[1])==0:\n",
    "        avg_lane.append(present[1])\n",
    "    else:\n",
    "        arr=w*np.array(present[1])+(1-w)*np.array(past[1])\n",
    "        avg_lane.append(arr.tolist())\n",
    "    \n",
    "    return avg_lane\n",
    "\n",
    "def detailImg(Img1, Img2, Img3, Img4, Img5, Img6, Img7, Img8, Img9):\n",
    "\n",
    "    #Combile all images and show results\n",
    "    ht=Img1.shape[0]\n",
    "    wd=Img1.shape[1]\n",
    "    DetailImg=np.zeros((3*ht, 3*wd, 3), dtype=np.uint8);\n",
    "    DetailImg[:ht,:wd]=Img1;\n",
    "    DetailImg[:ht,wd:2*wd]=cv2.merge((Img2,Img2,Img2));\n",
    "    DetailImg[:ht,2*wd:3*wd]=cv2.merge((Img3,Img3,Img3));\n",
    "    DetailImg[ht:2*ht,:wd]=cv2.merge((Img4,Img4,Img4));\n",
    "    DetailImg[ht:2*ht,wd:2*wd]=cv2.merge((Img5,Img5,Img5));\n",
    "    DetailImg[ht:2*ht,2*wd:3*wd]=Img6;\n",
    "    DetailImg[2*ht:3*ht,:wd]=Img7;\n",
    "    DetailImg[2*ht:3*ht,wd:2*wd]=Img8;\n",
    "    DetailImg[2*ht:3*ht,2*wd:3*wd]=Img9;\n",
    "\n",
    "    #Add titles for each step\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 1.5\n",
    "    color = (255,255,255)\n",
    "    thickness = 4\n",
    "    linetype = cv2.LINE_AA\n",
    "    w_off=10\n",
    "    h_off=80\n",
    "    cv2.putText(DetailImg, \"1.Input\", (w_off,h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"2.Grayscaling\", (wd+w_off,h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"3.Blurring\", (2*wd+w_off,h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"4.Edge Detection\", (w_off,ht+h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"5.Region Masking\", (wd+w_off,ht+h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"6.Hough Transform\", (2*wd+w_off,ht+h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"7.Slope Thresholding\", (w_off,2*ht+h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"8.Line averaging\", (wd+w_off,2*ht+h_off),font,scale,color,thickness,linetype)\n",
    "    cv2.putText(DetailImg, \"9.Final Visualization\", (2*wd+w_off,2*ht+h_off),font,scale,color,thickness,linetype)\n",
    "\n",
    "\n",
    "    #Create grid seperators\n",
    "    cv2.line(DetailImg, (wd, 0), (wd, 3*ht), [255,255,255], 2)\n",
    "    cv2.line(DetailImg, (2*wd, 0), (2*wd, 3*ht), [255,255,255], 2)\n",
    "    cv2.line(DetailImg, (0, ht), (3*wd, ht), [255,255,255], 2)\n",
    "    cv2.line(DetailImg, (0, 2*ht), (3*wd, 2*ht), [255,255,255], 2)\n",
    "    \n",
    "    return DetailImg\n",
    "\n",
    "def pipeline(Img, hyper, pastLaneLines=[[],[]]):\n",
    "    #STEP 1- INPUT and Resize\n",
    "    x=540;y=960;\n",
    "    scale_x=Img.shape[0]/x;\n",
    "    scale_y=Img.shape[1]/y;\n",
    "    if scale_x<scale_y:\n",
    "        dy=int(Img.shape[1]/scale_x);\n",
    "        Img1=cv2.resize(Img,(dy,x)) \n",
    "    else:\n",
    "        dx=int(Img.shape[0]/scale_y);\n",
    "        Img1=cv2.resize(Img,(y,dx), fy=scale_y) \n",
    "\n",
    "    #STEP 2- Grayscaling\n",
    "    Img2=grayscale(Img1)\n",
    "\n",
    "    #STEP 3- Blurring\n",
    "    Img3=gaussian_blur(Img2, hyper['blur_kernel_size'])\n",
    "\n",
    "    #STEP 4- Edge detection\n",
    "    Img4=canny(Img3, hyper['canny_low'], hyper['canny_high'])\n",
    "\n",
    "    #STEP 5- Region Masking\n",
    "    Low_Lf=[.05*Img1.shape[1],Img1.shape[0]]\n",
    "    Up_Lf=[.45*Img1.shape[1],.62*Img1.shape[0]]\n",
    "    Up_Rt=[.55*Img1.shape[1],.62*Img1.shape[0]]\n",
    "    Low_Rt=[.95*Img1.shape[1],Img1.shape[0]]\n",
    "    poly=np.array([[Low_Lf,Up_Lf,Up_Rt,Low_Rt]], dtype=np.int32)\n",
    "    Img5=region_of_interest(Img4, poly)\n",
    "\n",
    "    #STEP 6- Hough Transform\n",
    "    #Detecting line segments from edge pixels and creating blank image with lane lines\n",
    "    (Img6,lines)=hough_lines(Img5, hyper['hough_rho'], hyper['hough_theta'], hyper['hough_threshold'], \n",
    "                             hyper['hough_min_line_len'], hyper['hough_max_line_gap'])\n",
    "\n",
    "    #STEP 7- Slope Thresholding\n",
    "    (Img7,left_raw,right_raw)=slope_thresholding(Img6,lines)\n",
    "\n",
    "    #STEP 8- Averaging Raw lines\n",
    "    Img8, LaneLines=draw_lanes(Img7,left_raw,right_raw,pastLaneLines)\n",
    "    \n",
    "    #STEP 9- Final Visualization\n",
    "    #Superimposing lanes on original image\n",
    "    Img9=weighted_img(Img8, Img1)\n",
    "    \n",
    "    #Generate Detail Image\n",
    "    Img10=detailImg(Img1, Img2, Img3, Img4, Img5, Img6, Img7, Img8, Img9)\n",
    "    return Img9, Img10, LaneLines\n",
    "    \n",
    "\n",
    "Hyperparam={'blur_kernel_size':9,\n",
    "            'canny_low':30,\n",
    "            'canny_high':90,\n",
    "            'hough_rho':2,\n",
    "            'hough_theta':np.pi/90,\n",
    "            'hough_threshold':40,\n",
    "            'hough_min_line_len':30,\n",
    "            'hough_max_line_gap':20,};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Recorded Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "prevlane=[[],[]];\n",
    "def process_frame(Img):\n",
    "    global prevlane\n",
    "    Final, Detail, lane= pipeline(Img ,Hyperparam, prevlane)\n",
    "    prevlane=lane\n",
    "    return Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidWhiteRight.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidWhiteRight.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidWhiteRight.mp4\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "\n",
    "prevlane=[[],[]];\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)  #For shorter subclip\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/solidYellowLeft.mp4.\n",
      "Moviepy - Writing video test_videos_output/solidYellowLeft.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/solidYellowLeft.mp4\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "\n",
    "prevlane=[[],[]];\n",
    "#clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(26.9,27)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_frame)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/challenge.mp4.\n",
      "Moviepy - Writing video test_videos_output/challenge.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/challenge.mp4\n",
      "Wall time: 12.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "\n",
    "prevlane=[[],[]];\n",
    "#clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(4,7)\n",
    "#clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(0,2)\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_frame)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
